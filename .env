# vLLM Qwen3-Coder Configuration

# Model Configuration
MODEL_NAME=unsloth/Qwen3-Coder-30B-A3B-Instruct
SERVED_MODEL_NAME=qwen3-coder

# Context and Memory - Optimized for A40 48GB
MAX_MODEL_LEN=250000          # 250K context (A40 can handle more!)
GPU_MEMORY_UTILIZATION=0.92   # 92% GPU memory usage (safe for 48GB)
TENSOR_PARALLEL_SIZE=1        # Single GPU

# Data Types
DTYPE=bfloat16               # BF16 precision (better for FP8 KV cache)
KV_CACHE_DTYPE=fp8_e4m3      # FP8 KV cache for memory efficiency

# Performance - Tuned for 9 vCPU / 48GB RAM
MAX_NUM_SEQS=64              # Reduced for 9 vCPU (prevents CPU bottleneck)
SWAP_SPACE=8                 # Reduced swap space (enough RAM available)
BLOCK_SIZE=16                # Optimized block size for A40
NUM_SCHEDULER_STEPS=10       # Better batching for concurrent requests

# Network
PORT=8000
HOST=0.0.0.0

# Advanced Options
ENABLE_AUTO_TOOL_CHOICE=true
DISABLE_LOG_REQUESTS=true
TRUST_REMOTE_CODE=true

# Environment
VLLM_ATTENTION_BACKEND=FLASHINFER
HF_HOME=/app/.cache/huggingface